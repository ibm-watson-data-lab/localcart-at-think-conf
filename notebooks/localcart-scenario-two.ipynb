{"nbformat_minor": 1, "cells": [{"source": "# LocalCart scenario two: Static data analysis using Python, Apache Spark,  and PixieDust\n***\n\nIn this notebook, you'll first analyze customer demographics, such as, age, gender, income, and location. Then you'll combine that data with sales data to examine trends for product categories, transaction types, and product popularity. You'll load data from a previous notebook as well as from a public open data set, cleanse, shape, and enrich the data, and then visualize the data with the PixieDust library. Don't worry! PixieDust graphs don't require coding. By the end of the notebook, you'll understand how to combine data to gain insights about which customers you might target to increase sales.\n\n\n<img src=\"https://raw.githubusercontent.com/ibm-watson-data-lab/localcart-at-index-conf/master/images/static_analysis_flow.png\"></img>\n\n\nThis notebook runs on Python 2 with Spark 2.1, and PixieDust 1.1.7.", "cell_type": "markdown", "metadata": {}}, {"source": "<a id=\"toc\"></a>\n## Table of contents\n\n#### [Setup](#Setup)\n[Load data into the notebook](#Load-data-into-the-notebook)\n#### [Part 1. Explore customer demographics](#part1)\n[Prepare the customer data set](#Prepare-the-customer-data-set)<br>\n[Visualize customer demographics and locations](#Visualize-customer-demographics-and-locations)<br>\n[Enrich demographic information with open data](#Enrich-demographic-information-with-open-data)<br>   \n\n#### [Summary and next steps](#summary)", "cell_type": "markdown", "metadata": {}}, {"source": "## Setup\nYou need to import libraries and load the customer data into this notebook.\n\n- Install the most current packages so we can take advantage of the latest features.", "cell_type": "markdown", "metadata": {}}, {"source": "# run this cell\n# jinja2 version 2.10 is required\n#! pip install jinja2 --user --upgrade\n# pixiedust version 1.1.7.1 is required\n! pip install pixiedust --user --upgrade\n! pip install bokeh --user --upgrade", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "> **If any package was updated restart the kernel and reload the browser page.**", "cell_type": "markdown", "metadata": {}}, {"source": "Import the necessary libraries:", "cell_type": "markdown", "metadata": {}}, {"source": "import pixiedust\nimport pyspark.sql.functions as func\nimport pyspark.sql.types as types\nimport re\nimport json\nimport os\nimport requests  ", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "### Load data into the notebook\n\nThe data file contains both the customer demographic data that you'll analyzed in Part 1, and the sales transaction data for Part 2.", "cell_type": "markdown", "metadata": {}}, {"source": "raw_df = pixiedust.sampleData('https://raw.githubusercontent.com/ibm-watson-data-lab/localcart-at-think-conf/master/data/customers_orders1_opt.csv')", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "[Back to Table of Contents](#toc)\n<a id=\"part1\"></a>\n# Part 1. Explore customer demographics \nIn this part of the notebook, you'll prepare the customer data and then start learning about your customers by creating multiple charts and maps. ", "cell_type": "markdown", "metadata": {}}, {"source": "## Prepare the customer data set\nYou'll create a new DataFrame with just the data you need and then cleanse and enrich the data.\n\nExtract the columns that you want, remove duplicate customers, and add a column for aggregations:", "cell_type": "markdown", "metadata": {}}, {"source": "# Extract the customer information from the data set\n# CUSTNAME: string, GenderCode: string, ADDRESS1: string, CITY: string, STATE: string, COUNTRY_CODE: string, POSTAL_CODE: string, POSTAL_CODE_PLUS4: int, ADDRESS2: string, EMAIL_ADDRESS: string, PHONE_NUMBER: string, CREDITCARD_TYPE: string, LOCALITY: string, SALESMAN_ID: string, NATIONALITY: string, NATIONAL_ID: string, CREDITCARD_NUMBER: bigint, DRIVER_LICENSE: string, CUST_ID: int,\ncustomer_df = raw_df.select(\"CUST_ID\", \n                            \"CUSTNAME\", \n                            \"ADDRESS1\", \n                            \"ADDRESS2\", \n                            \"CITY\", \n                            \"POSTAL_CODE\", \n                            \"POSTAL_CODE_PLUS4\", \n                            \"STATE\", \n                            \"COUNTRY_CODE\", \n                            \"EMAIL_ADDRESS\", \n                            \"PHONE_NUMBER\",\n                            \"AGE\",\n                            \"GenderCode\",\n                            \"GENERATION\",\n                            \"NATIONALITY\", \n                            \"NATIONAL_ID\", \n                            \"DRIVER_LICENSE\").dropDuplicates()\n\ncustomer_df", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Notice that the data type of the AGE column is currently a string. Convert the AGE column to a numeric data type so you can run calculations on customer age.", "cell_type": "markdown", "metadata": {}}, {"source": "# ---------------------------------------\n# Cleanse age (enforce numeric data type) \n# ---------------------------------------\n\ndef getNumericVal(col):\n    \"\"\"\n    input: pyspark.sql.types.Column\n    output: the numeric value represented by col or None\n    \"\"\"\n    try:\n      return int(col)\n    except ValueError:\n      # age-33\n      match = re.match('^age\\-(\\d+)$', col)\n      if match:\n        try:\n          return int(match.group(1))\n        except ValueError:    \n          return None\n      return None  \n\ntoNumericValUDF = func.udf(lambda c: getNumericVal(c), types.IntegerType())\ncustomer_df = customer_df.withColumn(\"AGE\", toNumericValUDF(customer_df[\"AGE\"]))", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "The GenderCode column contains salutations instead of gender values. Derive the gender information for each customer based on the salutation and rename the GenderCode column to GENDER.", "cell_type": "markdown", "metadata": {}}, {"source": "# ------------------------------\n# Derive gender from salutation\n# ------------------------------\ndef deriveGender(col):\n    \"\"\" input: pyspark.sql.types.Column\n        output: \"male\", \"female\" or \"unknown\"\n    \"\"\"    \n    if col in ['Mr.', 'Master.']:\n        return 'male'\n    elif col in ['Mrs.', 'Miss.']:\n        return 'female'\n    else:\n        return 'unknown';\n    \nderiveGenderUDF = func.udf(lambda c: deriveGender(c), types.StringType())\ncustomer_df = customer_df.withColumn(\"GENDER\", deriveGenderUDF(customer_df[\"GenderCode\"]))\ncustomer_df.cache()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "## Explore the customer data set\n\nYou can quickly explore data sets using PixieDust's data set explorer. Invoke the `display()` command and click the table icon to review the schema and preview the data. Customize the options to display only a subset of the fields or rows or apply a filter (by clicking the funnel icon).", "cell_type": "markdown", "metadata": {}}, {"source": "display(customer_df)", "cell_type": "code", "metadata": {"pixiedust": {"displayParams": {"filter": "{\"regex\": \"False\", \"field\": \"AGE\", \"case_matter\": \"False\", \"value\": \"30\", \"constraint\": \"greater_than\"}", "rowCount": "200", "handlerId": "tableView", "no_margin": "true"}}}, "outputs": [], "execution_count": null}, {"source": "[Back to Table of Contents](#toc)\n## Visualize customer demographics and locations\n\nNow you're ready explore the customer base. Using simple charts, you can quickly see these characteristics:\n * Customer demographics (gender and age)\n * Customer locations (city, state, and country)\n\nYou'll create charts with the PixieDust library:\n\n - [View customers by gender in a pie chart](#View-customers-by-gender-in-a-pie-chart)\n - [View customers by generation in a bar chart](#View-customers-by-generation-in-a-bar-chart)\n - [View customers by age in a histogram chart](#View-customers-by-age-in-a-histogram-chart)\n - [View specific information with a filter function](#View-specific-information-with-a-filter-function)\n - [View customer density by location with a map](#View-customer-density-by-location-with-a-map)", "cell_type": "markdown", "metadata": {}}, {"source": "### View customers by gender in a pie chart\n\nRun the `display()` command and then configure the graph to show the percentages of male and female customers:\n\n1. Run the next cell. The PixieDust interactive widget appears.  \n1. Click the chart button and choose **Pie Chart**. The chart options tool appears.\n1. In the chart options, drag `GENDER` into the **Keys** box. \n1. In the **Aggregation** field, choose **COUNT**. \n1. Click **OK**. The pie chart appears.\n\nIf you want to make further changes, click **Options** to return to the chart options tool.", "cell_type": "markdown", "metadata": {}}, {"source": "display(customer_df)", "cell_type": "code", "metadata": {"pixiedust": {"displayParams": {"rowCount": "500", "handlerId": "pieChart", "keyFields": "GENDER", "chartsize": "50", "aggregation": "COUNT"}}}, "outputs": [], "execution_count": null}, {"source": "[Back to Table of Contents](#toc)\n### View customers by generation in a bar chart\nLook at how many customers you have per \"generation.\"\n\nRun the next cell and configure the graph: \n1. Choose **Bar Chart** as the chart type and configure the chart options as instructed below.\n2. Put `GENERATION` into the **Keys** box.\n4. Set **aggregation** to `COUNT`.", "cell_type": "markdown", "metadata": {}}, {"source": "display(customer_df)", "cell_type": "code", "metadata": {"pixiedust": {"displayParams": {"rowCount": "500", "handlerId": "barChart", "rendererId": "matplotlib", "chartsize": "51", "keyFields": "GENERATION", "aggregation": "COUNT"}}}, "outputs": [], "execution_count": null}, {"source": "You can use clustering to group customers, for example by geographic location. To group generations by country, select `COUNTRY_CODE` from the **Cluster by** list. ", "cell_type": "markdown", "metadata": {}}, {"source": "[Back to Table of Contents](#toc)\n### View customers by age in a histogram chart\nA generation is a broad age range. You can look at a smaller age range with a histogram chart. A histogram is like a bar chart except each bar represents a range of numbers, called a bin. You can customize the size of the age range by adjusting the bin size. The more bins you specify, the smaller the age range.\n\nRun the next cell and configure the graph:\n1. Choose **Histogram** as the chart type. Configure the chart options as follows.\n2. Put `AGE` into the **Values** box and click **OK**.\n3. Use the **Bin count** slider to specify the number of the bins. Try starting with 40.", "cell_type": "markdown", "metadata": {}}, {"source": "display(customer_df)", "cell_type": "code", "metadata": {"pixiedust": {"displayParams": {"rowCount": "500", "chartsize": "60", "valueFields": "AGE", "handlerId": "histogram", "binsize": "12"}}}, "outputs": [], "execution_count": null}, {"source": "[Back to Table of Contents](#toc)\n### View specific information with a filter function\n\nYou can filter records to restrict analysis by using the [PySpark DataFrame](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame) `filter()` function.\n\nIf you want to view the age distribution for a specific generation, uncomment the desired filter condition and run the next cell:", "cell_type": "markdown", "metadata": {}}, {"source": "# Data subsetting: display age distribution for a specific generation\n# (Chart type: histogram, Chart Options > Values: AGE)\n# to change the filter condition remove the # sign \ncondition = \"GENERATION = 'Baby_Boomers'\"\n#condition = \"GENERATION = 'Gen_X'\"\n#condition = \"GENERATION = 'Gen_Y'\"\n#condition = \"GENERATION = 'Gen_Z'\"\ndisplay(customer_df.filter(condition))\n", "cell_type": "code", "metadata": {"pixiedust": {"displayParams": {"GENERATION": "Baby_Boomers", "rowCount": "500", "chartsize": "60", "valueFields": "AGE", "handlerId": "histogram"}}, "scrolled": false}, "outputs": [], "execution_count": null}, {"source": "PixieDust supports basic filtering to make it easy to analyse data subsets. For example, to view the age distribution for a specific gender configure the chart as follows:\n\n  1. Choose `Histogram` as the chart type.\n  2. Put `AGE` into the **Values** box and click OK.\n  3. Click the filter button (looking like a funnel), and choose **GENDER** as field and `female` as value.\n  \nThe filter is only applied to the working data set and does not modify the input `customer_df`.\n", "cell_type": "markdown", "metadata": {}}, {"source": "display(customer_df)", "cell_type": "code", "metadata": {"pixiedust": {"displayParams": {"filter": "{\"regex\": \"false\", \"field\": \"GENDER\", \"case_matter\": \"false\", \"value\": \"female\", \"constraint\": \"None\"}", "rowCount": "500", "handlerId": "histogram", "no_margin": "true", "valueFields": "AGE", "GENDER": "female", "chartsize": "60"}}}, "outputs": [], "execution_count": null}, {"source": "You can also filter by location. For example, the following command creates a new DataFrame that filters for customers from the USA:", "cell_type": "markdown", "metadata": {}}, {"source": "condition = \"COUNTRY_CODE = 'US'\"\nus_customer_df = customer_df.filter(condition)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "You can pivot your analysis perspective based on aspects that are of interest to you by choosing different keys and clusters.\n\nCreate a bar chart and cluster the data.\n\nRun the next cell and configure the graph:\n1. Choose **Bar chart** as the chart type.\n2. Put `COUNTRY_CODE` into the **Keys** box.\n4. Set Aggregation to **COUNT**.\n5. Click **OK**. The chart displays the number of US customers.\n6. From the **Cluster By** list, choose **GENDER**. The chart shows the number of customers by gender.", "cell_type": "markdown", "metadata": {}}, {"source": "display(us_customer_df)", "cell_type": "code", "metadata": {"pixiedust": {"displayParams": {"chartsize": "76", "aggregation": "COUNT", "clusterby": "GENDER", "rowCount": "500", "handlerId": "barChart", "valueFields": "count", "keyFields": "COUNTRY_CODE", "legend": "true"}}}, "outputs": [], "execution_count": null}, {"source": "Now try to cluster the customers by state.\n\nA bar chart isn't the best way to show geographic location!", "cell_type": "markdown", "metadata": {}}, {"source": "[Back to Table of Contents](#toc)\n### View customer density by location with a map\nMaps are a much better way to view location data than other chart types. \n\nVisualize customer density by US state with a map.\n\nRun the next cell and configure the graph:\n1. Choose **Map** as the chart type.\n2. Put `STATE` into the **Keys** box.\n4. Set Aggregation to **COUNT**.\n5. Click **OK**. The map displays the number of US customers.\n6. From the **Renderer** list, choose **brunel**.\n   > PixieDust supports three map renderers: brunel, [mapbox](https://www.mapbox.com/) and Google. Note that the Mapbox renderer and the Google renderer require an API key or access token and supported features vary by renderer.", "cell_type": "markdown", "metadata": {}}, {"source": "display(us_customer_df)", "cell_type": "code", "metadata": {"pixiedust": {"displayParams": {"brunelMapType": "Map", "chartsize": "60", "aggregation": "COUNT", "rowCount": "500", "handlerId": "mapView", "valueFields": "", "rendererId": "brunel", "keyFields": "STATE"}}, "scrolled": false}, "outputs": [], "execution_count": null}, {"source": "You can explore more about customers in each state by changing the aggregation method, for example look at customer age ranges (avg, minimum, and maximum) by state. Simply Change the aggregation function to `AVG`, `MIN`, or `MAX` and choose `AGE` as value.", "cell_type": "markdown", "metadata": {"pixiedust": {"displayParams": {"rowCount": "500", "handlerId": "mapView", "valueFields": "count", "chartsize": "53", "keyFields": "STATE", "aggregation": "COUNT"}}}}, {"source": "[Back to Table of Contents](#toc)\n## Enrich demographic information with open data\nYou can easily combine other sources of data with your existing data. There's a lot of publicly available open data sets that can be very helpful. For example, knowing the approximate income level of your customers might help you target your marketing campaigns.\n\nRun the next cell to load [this data set](https://apsportal.ibm.com/exchange/public/entry/view/beb8c30a3f559e58716d983671b70337) from the United States Census Bureau into your notebook. The data set contains US household income statistics compiled at the zip code geography level.", "cell_type": "markdown", "metadata": {}}, {"source": "# Load median income information for all US ZIP codes from a public source\nincome_df = pixiedust.sampleData('https://apsportal.ibm.com/exchange-api/v1/entries/beb8c30a3f559e58716d983671b70337/data?accessKey=1c0b5b6d465fefec1ab529fde04997af')", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Now cleanse the income data set to remove the data that you don't need. Create a new DataFrame for this data:\n - The zip code, extracted from the GEOID column.\n - The column B19049e1, which contains the median household income for 2013.", "cell_type": "markdown", "metadata": {}}, {"source": "# ------------------------------\n# Helper: Extract ZIP code\n# ------------------------------\ndef extractZIPCode(col):\n    \"\"\" input: pyspark.sql.types.Column containing a geo code, like '86000US01001'\n        output: ZIP code\n    \"\"\"\n    m = re.match('^\\d+US(\\d\\d\\d\\d\\d)$',col)\n    if m:\n        return m.group(1)\n    else:\n        return None    \n    \ngetZIPCodeUDF = func.udf(lambda c: extractZIPCode(c), types.StringType())\nincome_df = income_df.select('GEOID', 'B19049e1').withColumnRenamed('B19049e1', 'MEDIAN_INCOME_IN_ZIP').withColumn(\"ZIP\", getZIPCodeUDF(income_df['GEOID']))\nincome_df", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Now perform a left outer join on the customer data set with the income data set, using the zip code as the join condition. For the complete syntax of joins, go to the <a href=\"https://spark.apache.org/docs/1.5.2/api/python/pyspark.sql.html#pyspark.sql.DataFrame\" target=\"_blank\" rel=\"noopener noreferrer\">pyspark DataFrame documentation</a> and scroll down to the `join` syntax. ", "cell_type": "markdown", "metadata": {}}, {"source": "us_customer_df = us_customer_df.join(income_df, us_customer_df.POSTAL_CODE == income_df.ZIP, 'left_outer').drop('GEOID').drop('ZIP')", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Now you can visualize the income distribution of your customers by zip code.\n Visualize income distribution for our customers.\nRun the next cell and configure the graph:\n1. Choose **Histogram** as the chart type.\n2. Put `MEDIAN_INCOME_IN_ZIP` into the **Values** box and click **OK**.", "cell_type": "markdown", "metadata": {}}, {"source": "display(us_customer_df)", "cell_type": "code", "metadata": {"pixiedust": {"displayParams": {"rowCount": "500", "chartsize": "52", "valueFields": "MEDIAN_INCOME_IN_ZIP", "handlerId": "histogram", "binsize": "25"}}}, "outputs": [], "execution_count": null}, {"source": "The majority of your customers live in zip codes where the median income is around 40,000 USD. ", "cell_type": "markdown", "metadata": {}}, {"source": "[Back to Table of Contents](#toc)\n", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"source": "<a id=\"summary\"></a>\n## Summary and next steps\n\nYou successfully completed this notebook!  \n\nCheck out other notebooks in this series: \n - Localcart scenario one: Dynamic data analysis and visualization\n - Localcart scenario three: Build a product recommendation engine\n - Localcart scenario four: Build a revenue dashboard using PixieApps\n\nCopyright \u00a9 2017, 2018 IBM. This notebook and its source code are released under the terms of the MIT License.", "cell_type": "markdown", "metadata": {"collapsed": true}}], "metadata": {"kernelspec": {"display_name": "Python 2 with Spark 2.1", "name": "python2-spark21", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.11", "name": "python", "pygments_lexer": "ipython2", "file_extension": ".py", "codemirror_mode": {"version": 2, "name": "ipython"}}}, "nbformat": 4}